# -*- coding: utf-8 -*-
"""Email Classifier For Akaike.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12BvbYq5F55lVCjkWSVrBWR1fVsnudSFW

**INSTALLING LIBRARIES**
"""

!pip install langdetect
!pip install deep-translator
!pip install emoji spacy
!pip install presidio-analyzer presidio-anonymizer spacy
!python -m spacy download en_core_web_lg

"""**Importing Libraries**"""

import pandas as pd
from tqdm import tqdm

"""**Data Preprocessing - Basic**"""

# reading csv file
df=pd.read_csv("combined_emails_with_natural_pii.csv")

# displaying shape, columns, columns-dtypes
print(f"SHAPE OF THE DATA FRAME : {df.shape}")
print(f"COLUMNS PRESENT IN DATA FRAME : {df.columns}")
print("DATA TYPES FOR COLUMNS")
print(df.dtypes)

# detecting the presence of missing values, duplicate rows
print(f"TOTAL NUMBER OF MISSING VALUES : {df.isna().sum().sum()}")
print("COLUMN WISE NUMBER OF MISSING VALUES")
print(df.isna().sum())
print(f"NUMBER OF DUPLICATE ROWS PRESENT IN DATA FRAME : {df[df.duplicated()].shape}")
print("ACTION ON DROPPING DUPLICATE VALUES")
if df[df.duplicated()].shape[0]>0:
  df=df.drop_duplicates()
  print("ACTION(DROPPED DUPLICATES)")
else:
  print("NO ACTION IS PERFORMED SINCE NO DUPLICATE ROWS FOUND")

# Number of unique values and unique values present in the column 'type'
print(f"NUMBER OF UNIQUE VALUES IN COLUMN 'type' :{df['type'].nunique()}")
print(f"UNIQUE VALUES PRESENT IN COLUMN 'type' :{list(df['type'].unique())}")

# Checking whether the data set is balanced or not
print("FREQUENCIES FOR EACH UNIQUE VALUE IN COLUMN 'type'")
df['type'].value_counts()

print("THIS IS AN IMBALANCED DATA SET")

# printing a single value from column 'email'
df['email'][0]

from langdetect import detect

def detect_languages_offline(df):
    language_list = []
    for i in tqdm(df['email'], desc="Detecting emails Language"):
        try:
            language_list.append(detect(i))
        except:
            language_list.append("unknown")

    frequencyDict = {}
    for lang in set(language_list):
        frequencyDict[lang] = language_list.count(lang)

    return frequencyDict

frequencyDict=detect_languages_offline(df)
print(frequencyDict)

import pandas as pd
from langdetect import detect
from deep_translator import GoogleTranslator
from tqdm import tqdm

# Translate all non-English emails to English
def translate_languages(df):
    translated_emails = []

    for text in tqdm(df['email'], desc="Translating emails"):
        try:
            detected_lang = detect(text)
            if detected_lang != 'en':
                translated_text = GoogleTranslator(source=detected_lang, target='en').translate(text)
            else:
                translated_text = text
        except Exception as e:
            # Fallback in case of error
            translated_text = text
        translated_emails.append(translated_text)

    df['email'] = translated_emails
    return df

print("BEFORE TRANSLATION : ")
lang_count=detect_languages_offline(df)
print(lang_count)
df=translate_languages(df)
lang_count=detect_languages_offline(df)
print("AFTER TRANSLATION : ")
print(lang_count)

df.to_csv("modified_csv.csv")

df['email'][0]

print("BEFORE TRANSLATION : ")
lang_count=detect_languages_offline(df)
print(lang_count)
df=translate_languages(df)
lang_count=detect_languages_offline(df)
print("AFTER TRANSLATION : ")
print(lang_count)

df.to_csv("modified(1).csv")

print("BEFORE TRANSLATION : ")
lang_count=detect_languages_offline(df)
print(lang_count)
df=translate_languages(df)
lang_count=detect_languages_offline(df)
print("AFTER TRANSLATION : ")
print(lang_count)

df.to_csv("modified(2).csv")

df=pd.read_csv("modified(2).csv")

"""**ADVANCED DATA PREPROCESSING**"""

# viewing sample data set with 5 rows
df.sample(5)

# dropping the column Unnamed: 0
df=df.drop(['Unnamed: 0'],axis=1)

# viewing columns
df.columns

# converting email to lower case
df['email']=df['email'].str.lower()
print("SAMPLE DOCUMENT AFTER LOWER CASING")
df.head(1)

# Removing html tags, url's, punctuation's and encoding the emoji's if used

import re
import string
import emoji
import pandas as pd

def clean_email_text(df):
    cleaned_emails = []

    for text in df['masked_email']:
        # 1. Remove HTML tags
        text = re.sub(r'<.*?>', '', text)

        # 2. Remove escape characters (like \n, \t, \r)
        text = re.sub(r'[\n\r\t]', ' ', text)

        # 3. Remove URLs
        text = re.sub(r'http\S+|www\.\S+', '', text)

        # 4. Remove punctuation
        text = ''.join(ch for ch in text if ch not in string.punctuation)

        # 5. Encode emojis (convert emojis to text like ':smile:')
        text = emoji.demojize(text)

        # Optional: Remove multiple spaces
        text = re.sub(r'\s+', ' ', text).strip()

        cleaned_emails.append(text)

    df['email'] = cleaned_emails
    return df

df=clean_email_text(df)

df['email'][0]

from presidio_analyzer import AnalyzerEngine, RecognizerRegistry, PatternRecognizer, Pattern
from presidio_anonymizer import AnonymizerEngine
from tqdm import tqdm
import pandas as pd

# Create analyzer
analyzer = AnalyzerEngine()

# Add custom recognizers (for Aadhar, CVV, Expiry)
aadhar_pattern = Pattern(name="Aadhar Pattern", regex=r"\b\d{4}[\s\-]?\d{4}[\s\-]?\d{4}\b", score=0.85)
cvv_pattern = Pattern(name="CVV Pattern", regex=r"\b\d{3}\b", score=0.8)
expiry_pattern = Pattern(name="Expiry Pattern", regex=r"\b(0[1-9]|1[0-2])/?(\d{2}|\d{4})\b", score=0.8)

aadhar_recognizer = PatternRecognizer(supported_entity="AADHAR_NUM", patterns=[aadhar_pattern])
cvv_recognizer = PatternRecognizer(supported_entity="CVV_NO", patterns=[cvv_pattern])
expiry_recognizer = PatternRecognizer(supported_entity="EXPIRY_NO", patterns=[expiry_pattern])

# Register them
analyzer.registry.add_recognizer(aadhar_recognizer)
analyzer.registry.add_recognizer(cvv_recognizer)
analyzer.registry.add_recognizer(expiry_recognizer)

# Map Presidio entity names to required ones
entity_label_map = {
    "PERSON": "full_name",
    "EMAIL_ADDRESS": "email",
    "PHONE_NUMBER": "phone_number",
    "DATE_TIME": "dob",
    "CREDIT_CARD": "credit_debit_no",
    "AADHAR_NUM": "aadhar_num",
    "CVV_NO": "cvv_no",
    "EXPIRY_NO": "expiry_no"
}

# Function to mask a single email
def mask_email_content(text):
    results = analyzer.analyze(text=text, entities=[], language='en')
    results = sorted(results, key=lambda r: r.start, reverse=True)

    for r in results:
        entity_name = entity_label_map.get(r.entity_type, None)
        if entity_name:
            text = text[:r.start] + f"[{entity_name}]" + text[r.end:]

    return text

def mask_dataframe_emails(df, text_column='email'):
    tqdm.pandas(desc="Masking PII/PCI with Presidio")
    df['masked_email'] = df[text_column].progress_apply(mask_email_content)
    return df

df = mask_dataframe_emails(df)

df['masked_email'][2]

df=clean_email_text(df)

df['masked_email'][2]

df.columns

df.to_csv("email.csv")

df=pd.read_csv("email.csv")
df.columns

df=df.drop(['Unnamed: 0'],axis=1)

df=df.rename({"masked_email":'email'},axis=1)

df.columns

"""**SOME NLP TECHNIQUES**"""

import spacy
import pandas as pd
from tqdm import tqdm

# Load spaCy English model
nlp = spacy.load("en_core_web_sm")

def process_emails(df):
    lemmatized_nostop = []

    for email in tqdm(df['email'], desc="Lemmatizing without stopwords"):
        doc = nlp(email)

        # Lemmatize and remove stopwords + punctuation
        lemmas = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]
        lemmatized_nostop.append(' '.join(lemmas))

    # Add new column to DataFrame
    df['email_lemmatized_nostopwords'] = lemmatized_nostop

    return df

df=process_emails(df)

df=pd.read_csv("email_lemmatized_nostopwords.csv")

df=df.drop(['Unnamed: 0', 'email'],axis=1)

df['email_lemmatized_nostopwords'][2]

df=df.rename({'email_lemmatized_nostopwords':'email'},axis=1)

"""**Exploratory Data Analysis**"""

def format_pct(pct):
    return f"{pct:.4f}%"
import matplotlib.pyplot as plt
plt.figure(figsize=(8,8))
plt.pie(df['type'].value_counts(),labels=df['type'].unique(),autopct=format_pct)
plt.title("Email Type Distribution", fontsize=16)
plt.show()

df=df.rename({'email_lemmatized_nostopwords':'email'},axis=1)
df.columns

!pip install wordcloud

from wordcloud import WordCloud
import matplotlib.pyplot as plt

def plot_wordcloud_from_column(df, column='email', title='Word Cloud'):
    # Combine all text in the column
    text = ' '.join(df[column].dropna().astype(str))

    # Generate word cloud
    wordcloud = WordCloud(width=1000, height=600, background_color='white', colormap='viridis').generate(text)

    # Plot
    plt.figure(figsize=(15, 8))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis('off')
    plt.title(title, fontsize=20)
    plt.show()

value_counts=df['type'].value_counts()
labels=value_counts.index
plt.bar(labels,value_counts)
plt.show()

# Example usage
plot_wordcloud_from_column(df[df['type']=='Incident'],title="Word Cloud For 'Incident' records")

# Example usage
plot_wordcloud_from_column(df[df['type']=='Request'],title="Word Cloud For 'Request' records")

# Example usage
plot_wordcloud_from_column(df[df['type']=='Change'],title="Word Cloud For 'Change' records")

# Example usage
plot_wordcloud_from_column(df[df['type']=='Problem'],title="Word Cloud For 'Problem' records")

"""**FEATURE ENGINEERING + MODEL SELECTION + MODEL IMPLEMENTATION + EVALUATION**"""

df.columns

"""**WITH TFIDF VECTORIZER**"""

from sklearn.model_selection import train_test_split
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import OrdinalEncoder
from sklearn.feature_extraction.text import *
from sklearn.metrics import classification_report, accuracy_score
import pandas as pd

# Prepare data
X = df['email']
y = df[['type']]

# Encode target
encoder = OrdinalEncoder()
y_encoded = encoder.fit_transform(y)

# Split data
X_train, X_test, y_train, y_test = train_test_split(
    X, y_encoded.ravel(), test_size=0.2, random_state=42, stratify=y_encoded
)

y_encoded[2]

from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer=TfidfVectorizer()
X_train_transformed=vectorizer.fit_transform(X_train)
x_test_transformed=vectorizer.transform(X_test)
model=MultinomialNB()
model.fit(X_train_transformed,y_train)
y_pred = model.predict(x_test_transformed)

print("MultinomialNB")
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred, target_names=encoder.categories_[0]))

from sklearn.linear_model import LogisticRegression
from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer=TfidfVectorizer()
X_train_transformed=vectorizer.fit_transform(X_train)
x_test_transformed=vectorizer.transform(X_test)
model=LogisticRegression(max_iter=1000)
model.fit(X_train_transformed,y_train)
y_pred = model.predict(x_test_transformed)

print("MultinomialNB")
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred, target_names=encoder.categories_[0]))

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score, classification_report
import pandas as pd

# Assuming X_train, X_test, y_train, y_test, encoder, df are already defined

# Vectorize the training and test data
vectorizer = TfidfVectorizer()
X_train_transformed = vectorizer.fit_transform(X_train)
X_test_transformed = vectorizer.transform(X_test)

# Train the LinearSVC model
model = LinearSVC()
model.fit(X_train_transformed, y_train)

# Predict on test data
y_pred = model.predict(X_test_transformed)

# Evaluation
print("LinearSVC")
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred, target_names=encoder.categories_[0]))

# Predict on a new example from the DataFrame
print("PREDICTIONS USING LINEAR SVC")
print(df.head(3))

data = df['email'][100]
print(data)

# Fix: Pass a list of the string directly
need_prediction = vectorizer.transform([data])
prediction = model.predict(need_prediction)
print("Prediction for new email:", prediction[0])

y_encoded[100]

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import pandas as pd

# Assuming X_train, X_test, y_train, y_test, encoder, df are already defined

# Vectorize the training and test data
vectorizer = TfidfVectorizer()
X_train_transformed = vectorizer.fit_transform(X_train)
X_test_transformed = vectorizer.transform(X_test)

# Train the RandomForestClassifier model
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train_transformed, y_train)

# Predict on test data
y_pred = model.predict(X_test_transformed)

# Evaluation
print("RandomForestClassifier")
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred, target_names=encoder.categories_[0]))

# Predict on a new example from the DataFrame
print("PREDICTIONS USING RANDOM FOREST")
print(df.head(3))

data = df['email'][10]
print(data)

# Predict
need_prediction = vectorizer.transform([data])
prediction = model.predict(need_prediction)
print("Prediction for new email:", prediction[0])

if prediction[0]==y_encoded[10]:
  print("=======================================================")
  print("CORRECT CLASSIFICATION")
  print("=======================================================")
else:
  print("=======================================================")
  print("WRONG CLASSIFICATION")
  print("=======================================================")

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report
import pandas as pd

# Assuming X_train, X_test, y_train, y_test, encoder, df, y_encoded are already defined

# Vectorize the training and test data
vectorizer = TfidfVectorizer()
X_train_transformed = vectorizer.fit_transform(X_train)
X_test_transformed = vectorizer.transform(X_test)

# Train the GradientBoostingClassifier model
model = GradientBoostingClassifier()
model.fit(X_train_transformed, y_train)

# Predict on test data
y_pred = model.predict(X_test_transformed)

# Evaluation
print("GradientBoostingClassifier")
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred, target_names=encoder.categories_[0]))

# Predict on a new example from the DataFrame
print("PREDICTIONS USING GRADIENT BOOSTING")
print(df.head(3))

data = df['email'][0]
print(data)

# Predict
need_prediction = vectorizer.transform([data])
prediction = model.predict(need_prediction)
print("Prediction for new email:", prediction[0])

# Check if prediction is correct
if prediction[0] == y_encoded[0]:
    print("=======================================================")
    print("CORRECT CLASSIFICATION")
    print("=======================================================")
else:
    print("=======================================================")
    print("WRONG CLASSIFICATION")
    print("=======================================================")

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report
import pandas as pd

# Assuming X_train, X_test, y_train, y_test, encoder, df, y_encoded are already defined

# Vectorize the training and test data
vectorizer = TfidfVectorizer()
X_train_transformed = vectorizer.fit_transform(X_train)
X_test_transformed = vectorizer.transform(X_test)

# Train the DecisionTreeClassifier model
model = DecisionTreeClassifier()
model.fit(X_train_transformed, y_train)

# Predict on test data
y_pred = model.predict(X_test_transformed)

# Evaluation
print("DecisionTreeClassifier")
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred, target_names=encoder.categories_[0]))

# Predict on a new example from the DataFrame
print("PREDICTIONS USING DECISION TREE")
print(df.head(3))

data = df['email'][10]
print(data)

# Predict
need_prediction = vectorizer.transform([data])
prediction = model.predict(need_prediction)
print("Prediction for new email:", prediction[0])

# Check if prediction is correct
if prediction[0] == y_encoded[10]:
    print("=======================================================")
    print("CORRECT CLASSIFICATION")
    print("=======================================================")
else:
    print("=======================================================")
    print("WRONG CLASSIFICATION")
    print("=======================================================")

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import SGDClassifier
from sklearn.metrics import accuracy_score, classification_report
import pandas as pd

# Assuming X_train, X_test, y_train, y_test, encoder, df, y_encoded are already defined

# Vectorize the training and test data
vectorizer = TfidfVectorizer()
X_train_transformed = vectorizer.fit_transform(X_train)
X_test_transformed = vectorizer.transform(X_test)

# Train the SGDClassifier model
model = SGDClassifier()
model.fit(X_train_transformed, y_train)

# Predict on test data
y_pred = model.predict(X_test_transformed)

# Evaluation
print("SGDClassifier")
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred, target_names=encoder.categories_[0]))

# Predict on a new example from the DataFrame
print("PREDICTIONS USING SGD CLASSIFIER")
print(df.head(3))

data = df['email'][0]
print(data)

# Predict
need_prediction = vectorizer.transform([data])
prediction = model.predict(need_prediction)
print("Prediction for new email:", prediction[0])

# Check if prediction is correct
if prediction[0] == y_encoded[0]:
    print("=======================================================")
    print("CORRECT CLASSIFICATION")
    print("=======================================================")
else:
    print("=======================================================")
    print("WRONG CLASSIFICATION")
    print("=======================================================")

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import RidgeClassifier
from sklearn.metrics import accuracy_score, classification_report
import pandas as pd

# Assuming X_train, X_test, y_train, y_test, encoder, df, y_encoded are already defined

# Vectorize the training and test data
vectorizer = TfidfVectorizer()
X_train_transformed = vectorizer.fit_transform(X_train)
X_test_transformed = vectorizer.transform(X_test)

# Train the RidgeClassifier model
model = RidgeClassifier()
model.fit(X_train_transformed, y_train)

# Predict on test data
y_pred = model.predict(X_test_transformed)

# Evaluation
print("RidgeClassifier")
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred, target_names=encoder.categories_[0]))

# Predict on a new example from the DataFrame
print("PREDICTIONS USING RIDGE CLASSIFIER")
print(df.head(3))

data = df['email'][10]
print(data)

# Predict
need_prediction = vectorizer.transform([data])
prediction = model.predict(need_prediction)
print("Prediction for new email:", prediction[0])

# Check if prediction is correct
if prediction[0] == y_encoded[10]:
    print("=======================================================")
    print("CORRECT CLASSIFICATION")
    print("=======================================================")
else:
    print("=======================================================")
    print("WRONG CLASSIFICATION")
    print("=======================================================")

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, classification_report
import pandas as pd

# Assuming X_train, X_test, y_train, y_test, encoder, df, y_encoded are already defined

# Vectorize the training and test data
vectorizer = TfidfVectorizer()
X_train_transformed = vectorizer.fit_transform(X_train)
X_test_transformed = vectorizer.transform(X_test)

# Train the MLPClassifier model
model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)
model.fit(X_train_transformed, y_train)

# Predict on test data
y_pred = model.predict(X_test_transformed)

# Evaluation
print("MLPClassifier")
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred, target_names=encoder.categories_[0]))

# Predict on a new example from the DataFrame
print("PREDICTIONS USING MLP CLASSIFIER")
print(df.head(3))

data = df['email'][10]
print(data)

# Predict
need_prediction = vectorizer.transform([data])
prediction = model.predict(need_prediction)
print("Prediction for new email:", prediction[0])

# Check if prediction is correct
if prediction[0] == y_encoded[10]:
    print("=======================================================")
    print("CORRECT CLASSIFICATION")
    print("=======================================================")
else:
    print("=======================================================")
    print("WRONG CLASSIFICATION")
    print("=======================================================")

"""**WITH COUNT VECTORIZER**"""

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report
import pandas as pd

# Assuming X_train, X_test, y_train, y_test, encoder, df, y_encoded are already defined

# Vectorize the training and test data
vectorizer = CountVectorizer()
X_train_transformed = vectorizer.fit_transform(X_train)
X_test_transformed = vectorizer.transform(X_test)

# Train the MultinomialNB model
model = MultinomialNB()
model.fit(X_train_transformed, y_train)

# Predict on test data
y_pred = model.predict(X_test_transformed)

# Evaluation
print("MultinomialNB")
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred, target_names=encoder.categories_[0]))

# Predict on a new example from the DataFrame
print("PREDICTIONS USING MULTINOMIAL NAIVE BAYES")
print(df.head(3))

data = df['email'][0]
print(data)

# Predict
need_prediction = vectorizer.transform([data])
prediction = model.predict(need_prediction)
print("Prediction for new email:", prediction[0])

# Check if prediction is correct
if prediction[0] == y_encoded[0]:
    print("=======================================================")
    print("CORRECT CLASSIFICATION")
    print("=======================================================")
else:
    print("=======================================================")
    print("WRONG CLASSIFICATION")
    print("=======================================================")

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
import pandas as pd

# Assuming X_train, X_test, y_train, y_test, encoder, df, y_encoded are already defined

# Vectorize the training and test data
vectorizer = CountVectorizer()
X_train_transformed = vectorizer.fit_transform(X_train)
X_test_transformed = vectorizer.transform(X_test)

# Train the LogisticRegression model
model = LogisticRegression(max_iter=1000)
model.fit(X_train_transformed, y_train)

# Predict on test data
y_pred = model.predict(X_test_transformed)

# Evaluation
print("LogisticRegression")
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred, target_names=encoder.categories_[0]))

# Predict on a new example from the DataFrame
print("PREDICTIONS USING LOGISTIC REGRESSION")
print(df.head(3))

data = df['email'][10]
print(data)

# Predict
need_prediction = vectorizer.transform([data])
prediction = model.predict(need_prediction)
print("Prediction for new email:", prediction[0])

# Check if prediction is correct
if prediction[0] == y_encoded[10]:
    print("=======================================================")
    print("CORRECT CLASSIFICATION")
    print("=======================================================")
else:
    print("=======================================================")
    print("WRONG CLASSIFICATION")
    print("=======================================================")

from sklearn.pipeline import make_pipeline
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, classification_report
import joblib  # <- for saving model

# Assuming X_train, y_train, X_test, y_test, and encoder are already defined

# Build and train the model
pipeline = make_pipeline(
    CountVectorizer(),
    MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)
)
pipeline.fit(X_train, y_train)

# Make predictions
y_pred = pipeline.predict(X_test)

# Evaluation
print("MLPClassifier")
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred, target_names=encoder.categories_[0]))

# Save the pipeline as a .pkl file
joblib.dump(pipeline, "mlp_classifier_pipeline.pkl")
print("Model saved as 'mlp_classifier_pipeline.pkl'")

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import SGDClassifier
from sklearn.metrics import accuracy_score, classification_report
import pandas as pd

# Assuming X_train, X_test, y_train, y_test, encoder, df, y_encoded are already defined

# Vectorize the training and test data
vectorizer = TfidfVectorizer()
X_train_transformed = vectorizer.fit_transform(X_train)
X_test_transformed = vectorizer.transform(X_test)

# Train the SGDClassifier model
model = SGDClassifier()
model.fit(X_train_transformed, y_train)

# Predict on test data
y_pred = model.predict(X_test_transformed)

# Evaluation
print("SGDClassifier")
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred, target_names=encoder.categories_[0]))

# Predict on a new example from the DataFrame
print("PREDICTIONS USING SGD CLASSIFIER")
print(df.head(3))

data = df['email'][5]
print(data)

# Predict
need_prediction = vectorizer.transform([data])
prediction = model.predict(need_prediction)
print("Prediction for new email:", prediction[0])

# Check if prediction is correct
if prediction[0] == y_encoded[5]:
    print("=======================================================")
    print("CORRECT CLASSIFICATION")
    print("=======================================================")
else:
    print("=======================================================")
    print("WRONG CLASSIFICATION")
    print("=======================================================")

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report
import pandas as pd

# Assuming X_train, X_test, y_train, y_test, encoder, df, y_encoded are already defined

# Vectorize the training and test data
vectorizer = CountVectorizer()
X_train_transformed = vectorizer.fit_transform(X_train)
X_test_transformed = vectorizer.transform(X_test)

# Train the DecisionTreeClassifier model
model = DecisionTreeClassifier()
model.fit(X_train_transformed, y_train)

# Predict on test data
y_pred = model.predict(X_test_transformed)

# Evaluation
print("DecisionTreeClassifier")
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred, target_names=encoder.categories_[0]))

# Predict on a new example from the DataFrame
print("PREDICTIONS USING DECISION TREE")
print(df.head(3))

data = df['email'][10]
print(data)

# Predict
need_prediction = vectorizer.transform([data])
prediction = model.predict(need_prediction)
print("Prediction for new email:", prediction[0])

# Check if prediction is correct
if prediction[0] == y_encoded[10]:
    print("=======================================================")
    print("CORRECT CLASSIFICATION")
    print("=======================================================")
else:
    print("=======================================================")
    print("WRONG CLASSIFICATION")
    print("=======================================================")

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report
import pandas as pd

# Assuming X_train, X_test, y_train, y_test, encoder, df, y_encoded are already defined

# Vectorize the training and test data
vectorizer = CountVectorizer()
X_train_transformed = vectorizer.fit_transform(X_train)
X_test_transformed = vectorizer.transform(X_test)

# Train the GradientBoostingClassifier model
model = GradientBoostingClassifier()
model.fit(X_train_transformed, y_train)

# Predict on test data
y_pred = model.predict(X_test_transformed)

# Evaluation
print("GradientBoostingClassifier")
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred, target_names=encoder.categories_[0]))

# Predict on a new example from the DataFrame
print("PREDICTIONS USING GRADIENT BOOSTING")
print(df.head(3))

data = df['email'][10]
print(data)

# Predict
need_prediction = vectorizer.transform([data])
prediction = model.predict(need_prediction)
print("Prediction for new email:", prediction[0])

# Check if prediction is correct
if prediction[0] == y_encoded[10]:
    print("=======================================================")
    print("CORRECT CLASSIFICATION")
    print("=======================================================")
else:
    print("=======================================================")
    print("WRONG CLASSIFICATION")
    print("=======================================================")

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import pandas as pd

# Assuming X_train, X_test, y_train, y_test, encoder, df, y_encoded are already defined

# Vectorize the training and test data
vectorizer = CountVectorizer()
X_train_transformed = vectorizer.fit_transform(X_train)
X_test_transformed = vectorizer.transform(X_test)

# Train the RandomForestClassifier model
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train_transformed, y_train)

# Predict on test data
y_pred = model.predict(X_test_transformed)

# Evaluation
print("RandomForestClassifier")
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred, target_names=encoder.categories_[0]))

# Predict on a new example from the DataFrame
print("PREDICTIONS USING RANDOM FOREST")
print(df.head(3))

data = df['email'][10]
print(data)

# Predict
need_prediction = vectorizer.transform([data])
prediction = model.predict(need_prediction)
print("Prediction for new email:", prediction[0])

# Check if prediction is correct
if prediction[0] == y_encoded[10]:
    print("=======================================================")
    print("CORRECT CLASSIFICATION")
    print("=======================================================")
else:
    print("=======================================================")
    print("WRONG CLASSIFICATION")
    print("=======================================================")

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score, classification_report
import pandas as pd

# Assuming X_train, X_test, y_train, y_test, encoder, df, y_encoded are already defined

# Vectorize the training and test data
vectorizer = CountVectorizer()
X_train_transformed = vectorizer.fit_transform(X_train)
X_test_transformed = vectorizer.transform(X_test)

# Train the LinearSVC model
model = LinearSVC()
model.fit(X_train_transformed, y_train)

# Predict on test data
y_pred = model.predict(X_test_transformed)

# Evaluation
print("LinearSVC")
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred, target_names=encoder.categories_[0]))

# Predict on a new example from the DataFrame
print("PREDICTIONS USING LINEAR SVC")
print(df.head(3))

data = df['email'][10]
print(data)

# Predict
need_prediction = vectorizer.transform([data])
prediction = model.predict(need_prediction)
print("Prediction for new email:", prediction[0])

# Check if prediction is correct
if prediction[0] == y_encoded[10]:
    print("=======================================================")
    print("CORRECT CLASSIFICATION")
    print("=======================================================")
else:
    print("=======================================================")
    print("WRONG CLASSIFICATION")
    print("=======================================================")

"""**USING SOME AUTOMATED MACHINE LEARNING FRAMEWORKS**"""

# using pycaret
!pip install pycaret

from pycaret.classification import *
exp = setup(data=df,target='type',text_features=['email'],preprocess=True)

best_model = compare_models()

# saving the model
save_model("et","Extra Trees Classifier")

df['type'][500]

data=pd.DataFrame(data=[df['email'][500]],columns=["email"])
df1=predict_model(best_model,data=data)
final_output=df1['prediction_label'].values[0]
print(final_output)

ensemble_model=tune_model(best_model)

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import OrdinalEncoder, RobustScaler
from sklearn.model_selection import train_test_split
import pandas as pd
import pickle

# ðŸ§  Load the dataset
df = pd.read_csv("email_lemmatized_nostopwords.csv")  # Replace with your actual CSV
X = df['email_lemmatized_nostopwords']
y = df[['type']]  # Make y 2D for OrdinalEncoder

# ðŸ“Š Encode labels
encoder = OrdinalEncoder()
y_encoded = encoder.fit_transform(y)

# ðŸ§ª Split dataset
X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)

# ðŸ”¡ Vectorize text with TF-IDF
vectorizer = CountVectorizer()
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# ðŸ§ª Robust Scaler (apply after converting sparse matrix to dense)
scaler = RobustScaler()
X_train_scaled = scaler.fit_transform(X_train_tfidf.toarray())
X_test_scaled = scaler.transform(X_test_tfidf.toarray())

# ðŸŒ² Train model
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train_scaled, y_train.ravel())

# ðŸ“ˆ Evaluation
y_pred = model.predict(X_test_scaled)
print("RandomForestClassifier")
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred, target_names=encoder.categories_[0]))

# ðŸŽ¯ Test prediction on a sample
print("PREDICTIONS USING RANDOM FOREST")
print(df.head(3))

sample_email = df['email'][10]
sample_vectorized = vectorizer.transform([sample_email])
sample_scaled = scaler.transform(sample_vectorized.toarray())
prediction = model.predict(sample_scaled)

print("Prediction for new email:", prediction[0])
print("Actual label:", y_encoded[10][0])

if prediction[0] == y_encoded[10][0]:
    print("âœ… CORRECT CLASSIFICATION")
else:
    print("âŒ WRONG CLASSIFICATION")

# ðŸ’¾ Save model, vectorizer, scaler, and encoder as .pkl
with open("model1.pkl", "wb") as model_file:
    pickle.dump(model, model_file)

with open("vectorizer.pkl", "wb") as vec_file:
    pickle.dump(vectorizer, vec_file)

with open("scaler.pkl", "wb") as scaler_file:
    pickle.dump(scaler, scaler_file)

with open("encoder.pkl", "wb") as enc_file:
    pickle.dump(encoder, enc_file)

